{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3370a489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Ortools\n",
      "  Using cached ortools-9.9.3963-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from Ortools) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.9/site-packages (from Ortools) (1.23.5)\n",
      "Collecting absl-py>=2.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting protobuf>=4.25.3\n",
      "  Using cached protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
      "Collecting immutabledict>=3.0.0\n",
      "  Using cached immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=2.0.0->Ortools) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas>=2.0.0->Ortools) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas>=2.0.0->Ortools) (2022.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->Ortools) (1.16.0)\n",
      "Installing collected packages: protobuf, immutabledict, absl-py, Ortools\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.12\n",
      "    Uninstalling protobuf-4.21.12:\n",
      "      Successfully uninstalled protobuf-4.21.12\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 1.4.0\n",
      "    Uninstalling absl-py-1.4.0:\n",
      "      Successfully uninstalled absl-py-1.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opentelemetry-proto 1.19.0 requires protobuf<5.0,>=3.19, but you have protobuf 5.26.1 which is incompatible.\n",
      "mysql-connector-python 8.0.31 requires protobuf<=3.20.1,>=3.11.0, but you have protobuf 5.26.1 which is incompatible.\n",
      "momento-wire-types 0.75.0 requires protobuf<5,>=3, but you have protobuf 5.26.1 which is incompatible.\n",
      "grpcio-tools 1.47.5 requires protobuf<4.0dev,>=3.12.0, but you have protobuf 5.26.1 which is incompatible.\n",
      "googleapis-common-protos 1.60.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
      "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Ortools-9.9.3963 absl-py-2.1.0 immutabledict-4.2.0 protobuf-5.26.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting docplex\n",
      "  Using cached docplex-2.25.236-py3-none-any.whl\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from docplex) (1.16.0)\n",
      "Installing collected packages: docplex\n",
      "Successfully installed docplex-2.25.236\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%pip install Ortools\n",
    "from ortools.sat.python import cp_model\n",
    "%pip install docplex\n",
    "from docplex.cp.model import CpoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edae13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset\n",
    "df_filter = pd.read_excel(\"Filter.xlsx\")\n",
    "\n",
    "# Drop the columns we don't use.\n",
    "df_drop = df_filter.drop(columns=['Number Of Teaching Weeks', 'Teaching Week Pattern'])\n",
    "\n",
    "# Only consider Lecture\n",
    "df_filter = df_drop[df_drop['Activity Type Name']=='*Lecture']\n",
    "df_L8 = df_filter[df_filter['Course Code'].str.contains('MATH08', regex=True)]\n",
    "\n",
    "# Delete the repeat same course with the same schedule\n",
    "df_L8 = df_L8.drop_duplicates(subset=['Course Name', 'Course Code', 'Scheduled Days', 'Scheduled Start Time', 'Scheduled End Time'])\n",
    "df_L8 = df_L8.reset_index(drop=True)\n",
    "df_L8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace93de",
   "metadata": {},
   "source": [
    "## Select the clash courses from Level 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3befb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "class CourseSchedulerDF:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe.copy()\n",
    "        self.dataframe['Delivery Semester'] = self.dataframe['Delivery Semester'].str.replace(r'\\*', '', regex=True).str.strip()\n",
    "\n",
    "    def _convert_time(self, time_str):\n",
    "        return datetime.strptime(time_str, \"%H:%M\").time()\n",
    "    \n",
    "    def find_overlapping_classes(self):\n",
    "        overlapping_classes = []\n",
    "        for i in range(len(self.dataframe)):\n",
    "            for j in range(i+1, len(self.dataframe)):\n",
    "                course_i = self.dataframe.iloc[i]\n",
    "                course_j = self.dataframe.iloc[j]\n",
    "                \n",
    "                # Convert the string times to time objects\n",
    "                start_i = self._convert_time(course_i[\"Scheduled Start Time\"])\n",
    "                end_i = self._convert_time(course_i[\"Scheduled End Time\"])\n",
    "                start_j = self._convert_time(course_j[\"Scheduled Start Time\"])\n",
    "                end_j = self._convert_time(course_j[\"Scheduled End Time\"])\n",
    "                \n",
    "                # Check if times overlap, if the semester is the same, and if the scheduled days are the same\n",
    "                if (start_i < end_j and start_j < end_i) and \\\n",
    "                   (course_i[\"Delivery Semester\"] == course_j[\"Delivery Semester\"]) and \\\n",
    "                   (course_i[\"Scheduled Days\"] == course_j[\"Scheduled Days\"]):\n",
    "                    overlapping_classes.append({\n",
    "                        \"Course 1\": course_i[\"Course Code\"],\n",
    "                        \"Course 2\": course_j[\"Course Code\"],\n",
    "                        \"Start Time Course 1\": course_i[\"Scheduled Start Time\"],\n",
    "                        \"End Time Course 1\": course_i[\"Scheduled End Time\"],\n",
    "                        \"Start Time Course 2\": course_j[\"Scheduled Start Time\"],\n",
    "                        \"End Time Course 2\": course_j[\"Scheduled End Time\"],\n",
    "                        \"Scheduled Days\": course_i[\"Scheduled Days\"],\n",
    "                        \"Delivery Semester\": course_i[\"Delivery Semester\"]\n",
    "                    })\n",
    "\n",
    "        return pd.DataFrame(overlapping_classes) if overlapping_classes else pd.DataFrame(columns=[\n",
    "            \"Course 1\", \"Course 2\",\n",
    "            \"Start Time Course 1\", \"End Time Course 1\",\n",
    "            \"Start Time Course 2\", \"End Time Course 2\",\n",
    "            \"Scheduled Days\", \"Delivery Semester\"\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0da8f7b-a134-4468-aa6a-005141bffe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Course 1   Course 2 Start Time Course 1 End Time Course 1  \\\n",
      "0  MATH08071  MATH08077               10:00             11:00   \n",
      "1  MATH08058  MATH08051               14:00             15:00   \n",
      "2  MATH08058  MATH08051               14:00             15:00   \n",
      "3  MATH08074  MATH08068               14:00             15:00   \n",
      "4  MATH08075  MATH08064               12:00             13:00   \n",
      "5  MATH08057  MATH08072               12:00             13:00   \n",
      "6  MATH08057  MATH08066               13:00             14:00   \n",
      "7  MATH08057  MATH08063               12:00             13:00   \n",
      "8  MATH08057  MATH08063               12:00             13:00   \n",
      "9  MATH08072  MATH08063               12:00             13:00   \n",
      "\n",
      "  Start Time Course 2 End Time Course 2 Scheduled Days Delivery Semester  \n",
      "0               10:00             11:00       Thursday             SEM 1  \n",
      "1               14:00             15:00         Monday             SEM 2  \n",
      "2               14:00             15:00       Thursday             SEM 2  \n",
      "3               14:00             15:00       Thursday             SEM 1  \n",
      "4               12:00             13:00        Tuesday             SEM 2  \n",
      "5               12:00             13:00       Thursday             SEM 1  \n",
      "6               13:00             14:00       Thursday             SEM 1  \n",
      "7               12:00             13:00         Friday             SEM 1  \n",
      "8               12:00             13:00         Monday             SEM 1  \n",
      "9               12:00             13:00        Tuesday             SEM 1  \n"
     ]
    }
   ],
   "source": [
    "scheduler = CourseSchedulerDF(df_L8)\n",
    "overlaps_df = scheduler.find_overlapping_classes()\n",
    "\n",
    "# Print the DataFrame\n",
    "print(overlaps_df)\n",
    "\n",
    "# Save the DataFrame to an Excel file in the current working directory\n",
    "output_file_name = 'overlapping_courses.xlsx'\n",
    "overlaps_df.to_excel(output_file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5701d4c2-5aa9-4d94-8b97-164f85883e51",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f7ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# Create model\n",
    "model = CpoModel()\n",
    "\n",
    "from ortools.sat.python import cp_model\n",
    "\n",
    "# Create the CP model\n",
    "model = cp_model.CpModel()\n",
    "\n",
    "# Let's define our sets based on your description\n",
    "S = set_of_lecture_sections  # This will be a set of all lecture sections\n",
    "N = set_of_student_numbers  # This will be a set of total enrollment numbers\n",
    "D = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri']  # Days of the week\n",
    "H = list(range(9, 18))  # Teaching hours (9 AM to 5 PM)\n",
    "L = set_of_class_locations  # This will be a set of all class locations\n",
    "C = set_of_classroom_capacity  # This will be a set of classroom capacities\n",
    "M = set_of_compulsory_courses  # This will be a set of compulsory courses\n",
    "K = set_of_students  # This will be a set of all individual students\n",
    "Y = {8, 9, 10, 11}  # Year levels\n",
    "\n",
    "# Assuming we have a way to extract this data from the provided DataFrames:\n",
    "# For example, compulsory_courses might be a dictionary where the key is the year level\n",
    "# and the value is a list of compulsory courses for that year\n",
    "compulsory_courses = {\n",
    "    8: ['MATH08'],\n",
    "    # Add other year levels and their courses here\n",
    "}\n",
    "\n",
    "# We need to create a decision variable for each class that represents when and where it is scheduled\n",
    "class_vars = {}\n",
    "for section in S:\n",
    "    for day in D:\n",
    "        for hour in H:\n",
    "            for location in L:\n",
    "                # Binary variable: 1 if the section is scheduled at this time and location, 0 otherwise\n",
    "                class_vars[(section, day, hour, location)] = model.NewBoolVar(f'section_{section}_{day}_{hour}_{location}')\n",
    "\n",
    "# Add constraints\n",
    "# Each section can only be scheduled once per day\n",
    "for section in S:\n",
    "    for day in D:\n",
    "        model.Add(sum(class_vars[(section, day, hour, location)] for hour in H for location in L) <= 1)\n",
    "\n",
    "# Compulsory courses for the same year level cannot clash\n",
    "for year_level in Y:\n",
    "    for day in D:\n",
    "        for hour in H:\n",
    "            model.Add(sum(class_vars[(section, day, hour, location)]\n",
    "                          for section in compulsory_courses[year_level]\n",
    "                          for location in L) <= 1)\n",
    "\n",
    "# No overlapping classes in the same location\n",
    "for location in L:\n",
    "    for day in D:\n",
    "        for hour in H:\n",
    "            model.Add(sum(class_vars[(section, day, hour, location)] for section in S) <= 1)\n",
    "\n",
    "# ... additional constraints for professors, classroom capacities, etc.\n",
    "\n",
    "# Create the solver and solve the model\n",
    "solver = cp_model.CpSolver()\n",
    "status = solver.Solve(model)\n",
    "\n",
    "if status == cp_model.OPTIMAL or status == cp_model.FEASIBLE:\n",
    "    print('Solution found:')\n",
    "    # Extract the solution (where each section is scheduled)\n",
    "    for section in S:\n",
    "        for day in D:\n",
    "            for hour in H:\n",
    "                for location in L:\n",
    "                    if solver.Value(class_vars[(section, day, hour, location)]) == 1:\n",
    "                        print(f'Section {section} is scheduled on {day} at {hour}:00 in {location}')\n",
    "else:\n",
    "    print('No solution found.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25461c-2409-43ad-9358-afe4fb1ae84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates based on 'Course Name'\n",
    "df_unique_courses = df_L8.drop_duplicates(subset=['Course Name'])\n",
    "\n",
    "# Reset index to start from 1 after dropping duplicates\n",
    "df_unique_courses.reset_index(drop=True, inplace=True)\n",
    "df_unique_courses.index += 1\n",
    "\n",
    "\n",
    "# Assuming df is your existing dataframe with the 'Course Code' column\n",
    "df_course_codes = df_unique_courses[['Course Code']].copy()\n",
    "df_course_codes.reset_index(drop=True, inplace=True)\n",
    "df_course_codes.index += 1\n",
    "df_course_codes['Serial Number'] = df_course_codes.index\n",
    "df_course_codes = df_course_codes['Course Code']\n",
    "print(df_course_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a0eb8-657c-4f53-8912-c55a86643418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c9c1da-af0a-4347-828a-3fa5c871a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your existing dataframe with the 'Course Code' column\n",
    "df_course_codes = df_unique_courses[['Course Code']].copy()\n",
    "df_course_codes.reset_index(drop=True, inplace=True)\n",
    "df_course_codes.index += 1\n",
    "df_course_codes['Serial Number'] = df_course_codes.index\n",
    "df_course_codes = df_course_codes['Course Code']\n",
    "print(df_course_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea6302-a188-42dd-91e6-63540bde2f55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
